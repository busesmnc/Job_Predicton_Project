Logistic Regression Model Evaluation Results
==================================================

1. Classification Metrics:
------------------------------
Accuracy: 0.9150
Precision (weighted): 0.9276
Recall/Sensitivity (weighted): 0.9150
F1-measure (weighted): 0.9125

2. Confusion Matrix:
------------------------------
Shape: (29, 29)

[[19  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0 16  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  1 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  3  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  2  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  1  1  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  1  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  1  2  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  1  0  1  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  2  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  3  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 24  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0
   0  0  0  0  0]
 [ 0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0
   0  0  0  0  0]
 [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2
  19  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1
   0  9  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0 18  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  4  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  8]]

3. Detailed Classification Report:
------------------------------
              precision    recall  f1-score   support

           1       1.00      0.95      0.97        20
           2       0.59      0.94      0.73        17
           3       0.88      0.94      0.91        16
           4       0.50      0.67      0.57         9
           5       1.00      0.33      0.50         3
           6       0.93      0.87      0.90        15
           7       1.00      1.00      1.00         9
           8       1.00      1.00      1.00         5
           9       0.00      0.00      0.00         1
          10       1.00      1.00      1.00         2
          11       0.89      0.94      0.92        18
          12       1.00      0.67      0.80         3
          13       0.00      0.00      0.00         1
          14       1.00      1.00      1.00         5
          15       0.80      0.67      0.73         6
          16       1.00      0.25      0.40         4
          17       1.00      0.75      0.86         4
          18       1.00      1.00      1.00        24
          19       1.00      1.00      1.00        11
          20       1.00      1.00      1.00         4
          21       1.00      1.00      1.00        20
          22       1.00      0.83      0.91        12
          23       1.00      0.91      0.95        11
          24       0.89      1.00      0.94        25
          25       1.00      0.90      0.95        21
          26       1.00      0.90      0.95        10
          27       1.00      1.00      1.00        18
          28       1.00      1.00      1.00         4
          29       1.00      1.00      1.00         8

    accuracy                           0.92       306
   macro avg       0.88      0.81      0.83       306
weighted avg       0.93      0.92      0.91       306
